<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Data Analysis in Ecology with R and Stan</title>
  <meta name="description" content="This GitHub-book is collection of updates and additional material to the book Bayesian Data Analysis in Ecology Using Linear Models with R, BUGS, and STAN.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Data Analysis in Ecology with R and Stan" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="images/cover.jpg" />
  <meta property="og:description" content="This GitHub-book is collection of updates and additional material to the book Bayesian Data Analysis in Ecology Using Linear Models with R, BUGS, and STAN." />
  <meta name="github-repo" content="TobiasRoth/BDAEcology" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Data Analysis in Ecology with R and Stan" />
  
  <meta name="twitter:description" content="This GitHub-book is collection of updates and additional material to the book Bayesian Data Analysis in Ecology Using Linear Models with R, BUGS, and STAN." />
  <meta name="twitter:image" content="images/cover.jpg" />

<meta name="author" content="Fränzi Korner-Nievergelt and Tobias Roth">


<meta name="date" content="2018-11-27">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="PART-I.html">
<link rel="next" href="analyses-steps.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="Settings\style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#why-this-book"><i class="fa fa-check"></i>Why this book?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-this-book"><i class="fa fa-check"></i>About this book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#how-to-contribute"><i class="fa fa-check"></i>How to contribute?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgments"><i class="fa fa-check"></i>Acknowledgments</a></li>
</ul></li>
<li class="part"><span><b>I R FOR ECOLOGISTS</b></span></li>
<li class="chapter" data-level="1" data-path="PART-I.html"><a href="PART-I.html"><i class="fa fa-check"></i><b>1</b> Introduction to PART I</a><ul>
<li class="chapter" data-level="1.1" data-path="PART-I.html"><a href="PART-I.html#further-reading"><i class="fa fa-check"></i><b>1.1</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="basics.html"><a href="basics.html"><i class="fa fa-check"></i><b>2</b> Prerequisits: Basic statistical terms</a><ul>
<li class="chapter" data-level="2.1" data-path="basics.html"><a href="basics.html#scale-of-measurement"><i class="fa fa-check"></i><b>2.1</b> Scale of measurement</a></li>
<li class="chapter" data-level="2.2" data-path="basics.html"><a href="basics.html#correlations"><i class="fa fa-check"></i><b>2.2</b> Correlations</a><ul>
<li class="chapter" data-level="2.2.1" data-path="basics.html"><a href="basics.html#basics-of-variances-covariances-and-correlations"><i class="fa fa-check"></i><b>2.2.1</b> Basics of variances, covariances and correlations</a></li>
<li class="chapter" data-level="2.2.2" data-path="basics.html"><a href="basics.html#pearson-correlation-coefficient"><i class="fa fa-check"></i><b>2.2.2</b> Pearson correlation coefficient</a></li>
<li class="chapter" data-level="2.2.3" data-path="basics.html"><a href="basics.html#spearman-correlation-coefficient"><i class="fa fa-check"></i><b>2.2.3</b> Spearman correlation coefficient</a></li>
<li class="chapter" data-level="2.2.4" data-path="basics.html"><a href="basics.html#kendalls-tau"><i class="fa fa-check"></i><b>2.2.4</b> Kendall’s tau</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="basics.html"><a href="basics.html#principal-components-analyses-pca"><i class="fa fa-check"></i><b>2.3</b> Principal components analyses PCA</a><ul>
<li class="chapter" data-level="2.3.1" data-path="basics.html"><a href="basics.html#inferential-statistics"><i class="fa fa-check"></i><b>2.3.1</b> Inferential statistics</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="basics.html"><a href="basics.html#standard-deviation-and-standard-error"><i class="fa fa-check"></i><b>2.4</b> Standard deviation and standard error</a></li>
<li class="chapter" data-level="2.5" data-path="basics.html"><a href="basics.html#central-limit-theorem-law-of-large-numbers"><i class="fa fa-check"></i><b>2.5</b> Central limit theorem / law of large numbers</a></li>
<li class="chapter" data-level="2.6" data-path="basics.html"><a href="basics.html#bayes-theorem"><i class="fa fa-check"></i><b>2.6</b> Bayes theorem</a></li>
<li class="chapter" data-level="2.7" data-path="basics.html"><a href="basics.html#bayes-theorem-for-continuous-parameters"><i class="fa fa-check"></i><b>2.7</b> Bayes theorem for continuous parameters</a></li>
<li class="chapter" data-level="2.8" data-path="basics.html"><a href="basics.html#single-parameter-model"><i class="fa fa-check"></i><b>2.8</b> Single parameter model</a></li>
<li class="chapter" data-level="2.9" data-path="basics.html"><a href="basics.html#a-model-with-two-parameters"><i class="fa fa-check"></i><b>2.9</b> A model with two parameters</a></li>
<li class="chapter" data-level="2.10" data-path="basics.html"><a href="basics.html#t-distribution"><i class="fa fa-check"></i><b>2.10</b> t-distribution</a></li>
<li class="chapter" data-level="2.11" data-path="basics.html"><a href="basics.html#frequentist-one-sample-t-test"><i class="fa fa-check"></i><b>2.11</b> Frequentist one-sample t-test</a></li>
<li class="chapter" data-level="2.12" data-path="basics.html"><a href="basics.html#nullhypothesis-test"><i class="fa fa-check"></i><b>2.12</b> Nullhypothesis test</a></li>
<li class="chapter" data-level="2.13" data-path="basics.html"><a href="basics.html#confidence-interval"><i class="fa fa-check"></i><b>2.13</b> Confidence interval</a></li>
<li class="chapter" data-level="2.14" data-path="basics.html"><a href="basics.html#posterior-distribution"><i class="fa fa-check"></i><b>2.14</b> Posterior distribution</a></li>
<li class="chapter" data-level="2.15" data-path="basics.html"><a href="basics.html#posterior-probability"><i class="fa fa-check"></i><b>2.15</b> Posterior probability</a></li>
<li class="chapter" data-level="2.16" data-path="basics.html"><a href="basics.html#monte-carlo-simulation-parametric-bootstrap"><i class="fa fa-check"></i><b>2.16</b> Monte Carlo simulation (parametric bootstrap)</a></li>
<li class="chapter" data-level="2.17" data-path="basics.html"><a href="basics.html#methods-for-getting-the-posterior-distribution"><i class="fa fa-check"></i><b>2.17</b> 3 methods for getting the posterior distribution</a></li>
<li class="chapter" data-level="2.18" data-path="basics.html"><a href="basics.html#grid-approximation"><i class="fa fa-check"></i><b>2.18</b> Grid approximation</a></li>
<li class="chapter" data-level="2.19" data-path="basics.html"><a href="basics.html#monte-carlo-simulations"><i class="fa fa-check"></i><b>2.19</b> Monte Carlo simulations</a></li>
<li class="chapter" data-level="2.20" data-path="basics.html"><a href="basics.html#comparison-of-the-locations-between-two-groups"><i class="fa fa-check"></i><b>2.20</b> Comparison of the locations between two groups</a></li>
<li class="chapter" data-level="2.21" data-path="basics.html"><a href="basics.html#difference-between-two-means"><i class="fa fa-check"></i><b>2.21</b> Difference between two means</a></li>
<li class="chapter" data-level="2.22" data-path="basics.html"><a href="basics.html#two-sample-t-test"><i class="fa fa-check"></i><b>2.22</b> Two-sample t-test</a></li>
<li class="chapter" data-level="2.23" data-path="basics.html"><a href="basics.html#wilxocon-test"><i class="fa fa-check"></i><b>2.23</b> Wilxocon test</a></li>
<li class="chapter" data-level="2.24" data-path="basics.html"><a href="basics.html#randomisation-test"><i class="fa fa-check"></i><b>2.24</b> Randomisation test</a></li>
<li class="chapter" data-level="2.25" data-path="basics.html"><a href="basics.html#bootstrap"><i class="fa fa-check"></i><b>2.25</b> Bootstrap</a></li>
<li class="chapter" data-level="2.26" data-path="basics.html"><a href="basics.html#f-distribution"><i class="fa fa-check"></i><b>2.26</b> F-distribution</a><ul>
<li class="chapter" data-level="2.26.1" data-path="basics.html"><a href="basics.html#analysis-of-variance-anova"><i class="fa fa-check"></i><b>2.26.1</b> Analysis of variance ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="2.27" data-path="basics.html"><a href="basics.html#chisquare-test"><i class="fa fa-check"></i><b>2.27</b> Chisquare test</a></li>
<li class="chapter" data-level="2.28" data-path="basics.html"><a href="basics.html#bayesian-way-of-analysing-correlations-between-categorical-variables"><i class="fa fa-check"></i><b>2.28</b> Bayesian way of analysing correlations between categorical variables</a></li>
<li class="chapter" data-level="2.29" data-path="basics.html"><a href="basics.html#summary"><i class="fa fa-check"></i><b>2.29</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="analyses-steps.html"><a href="analyses-steps.html"><i class="fa fa-check"></i><b>3</b> Data analysis step by step</a><ul>
<li class="chapter" data-level="3.1" data-path="analyses-steps.html"><a href="analyses-steps.html#step1"><i class="fa fa-check"></i><b>3.1</b> Plausibility of Data</a></li>
<li class="chapter" data-level="3.2" data-path="analyses-steps.html"><a href="analyses-steps.html#step2"><i class="fa fa-check"></i><b>3.2</b> Relationships</a></li>
<li class="chapter" data-level="3.3" data-path="analyses-steps.html"><a href="analyses-steps.html#step3"><i class="fa fa-check"></i><b>3.3</b> Error Distribution</a></li>
<li class="chapter" data-level="3.4" data-path="analyses-steps.html"><a href="analyses-steps.html#step4"><i class="fa fa-check"></i><b>3.4</b> Preparation of Explanatory Variables</a></li>
<li class="chapter" data-level="3.5" data-path="analyses-steps.html"><a href="analyses-steps.html#step5"><i class="fa fa-check"></i><b>3.5</b> Data Structure</a></li>
<li class="chapter" data-level="3.6" data-path="analyses-steps.html"><a href="analyses-steps.html#step6"><i class="fa fa-check"></i><b>3.6</b> Fit the Model</a></li>
<li class="chapter" data-level="3.7" data-path="analyses-steps.html"><a href="analyses-steps.html#step7"><i class="fa fa-check"></i><b>3.7</b> Check Model</a></li>
<li class="chapter" data-level="3.8" data-path="analyses-steps.html"><a href="analyses-steps.html#step8"><i class="fa fa-check"></i><b>3.8</b> Model Uncertainty</a></li>
<li class="chapter" data-level="3.9" data-path="analyses-steps.html"><a href="analyses-steps.html#step9"><i class="fa fa-check"></i><b>3.9</b> Draw Conclusions</a></li>
<li class="chapter" data-level="" data-path="analyses-steps.html"><a href="analyses-steps.html#further-reading-1"><i class="fa fa-check"></i>Further reading</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="datamanip.html"><a href="datamanip.html"><i class="fa fa-check"></i><b>4</b> Data preparation</a><ul>
<li class="chapter" data-level="4.1" data-path="datamanip.html"><a href="datamanip.html#basic-operations"><i class="fa fa-check"></i><b>4.1</b> Basic operations</a></li>
<li class="chapter" data-level="4.2" data-path="datamanip.html"><a href="datamanip.html#joindata"><i class="fa fa-check"></i><b>4.2</b> Joining tables</a></li>
<li class="chapter" data-level="4.3" data-path="datamanip.html"><a href="datamanip.html#further-reading-2"><i class="fa fa-check"></i><b>4.3</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="distributions.html"><a href="distributions.html"><i class="fa fa-check"></i><b>5</b> Probability distributions</a><ul>
<li class="chapter" data-level="5.1" data-path="distributions.html"><a href="distributions.html#introduction"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="distributions.html"><a href="distributions.html#normal-distribution"><i class="fa fa-check"></i><b>5.2</b> Normal distribution</a></li>
<li class="chapter" data-level="5.3" data-path="distributions.html"><a href="distributions.html#poisson-distribution"><i class="fa fa-check"></i><b>5.3</b> Poisson distribution</a></li>
<li class="chapter" data-level="5.4" data-path="distributions.html"><a href="distributions.html#gamma-distribution"><i class="fa fa-check"></i><b>5.4</b> Gamma distribution</a><ul>
<li class="chapter" data-level="5.4.1" data-path="distributions.html"><a href="distributions.html#cauchydistri"><i class="fa fa-check"></i><b>5.4.1</b> Cauchy distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="figures.html"><a href="figures.html"><i class="fa fa-check"></i><b>6</b> Visualizations</a><ul>
<li class="chapter" data-level="6.1" data-path="figures.html"><a href="figures.html#short-checklist-for-figures"><i class="fa fa-check"></i><b>6.1</b> Short Checklist for figures</a></li>
<li class="chapter" data-level="" data-path="figures.html"><a href="figures.html#further-reading-3"><i class="fa fa-check"></i>Further reading</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="rgis.html"><a href="rgis.html"><i class="fa fa-check"></i><b>7</b> Spatial analyses and maps</a><ul>
<li class="chapter" data-level="7.1" data-path="rgis.html"><a href="rgis.html#data-types"><i class="fa fa-check"></i><b>7.1</b> Data types</a><ul>
<li class="chapter" data-level="7.1.1" data-path="rgis.html"><a href="rgis.html#rasterdata"><i class="fa fa-check"></i><b>7.1.1</b> Raster data</a></li>
<li class="chapter" data-level="7.1.2" data-path="rgis.html"><a href="rgis.html#geometrydata"><i class="fa fa-check"></i><b>7.1.2</b> Geometry data</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="rgis.html"><a href="rgis.html#basic-functions"><i class="fa fa-check"></i><b>7.2</b> Basic functions</a><ul>
<li class="chapter" data-level="7.2.1" data-path="rgis.html"><a href="rgis.html#coordinate-systems"><i class="fa fa-check"></i><b>7.2.1</b> Coordinate systems</a></li>
<li class="chapter" data-level="7.2.2" data-path="rgis.html"><a href="rgis.html#joining-spatial-data"><i class="fa fa-check"></i><b>7.2.2</b> Joining spatial data</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="rgis.html"><a href="rgis.html#further-reading-4"><i class="fa fa-check"></i><b>7.3</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="reproducible.html"><a href="reproducible.html"><i class="fa fa-check"></i><b>8</b> Reproducible Research</a><ul>
<li class="chapter" data-level="8.1" data-path="reproducible.html"><a href="reproducible.html#introduction-1"><i class="fa fa-check"></i><b>8.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2" data-path="reproducible.html"><a href="reproducible.html#further-reading-5"><i class="fa fa-check"></i><b>8.2</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="furthertopics.html"><a href="furthertopics.html"><i class="fa fa-check"></i><b>9</b> Further topics</a><ul>
<li class="chapter" data-level="9.1" data-path="furthertopics.html"><a href="furthertopics.html#bioacoustic-analyse"><i class="fa fa-check"></i><b>9.1</b> Bioacoustic analyse</a></li>
<li class="chapter" data-level="9.2" data-path="furthertopics.html"><a href="furthertopics.html#python"><i class="fa fa-check"></i><b>9.2</b> Python</a></li>
</ul></li>
<li class="part"><span><b>II BAYESIAN DATA ANALYSIS</b></span></li>
<li class="chapter" data-level="10" data-path="PART-II.html"><a href="PART-II.html"><i class="fa fa-check"></i><b>10</b> Introduction to PART II</a><ul>
<li class="chapter" data-level="" data-path="PART-II.html"><a href="PART-II.html#further-reading-6"><i class="fa fa-check"></i>Further reading</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="priors.html"><a href="priors.html"><i class="fa fa-check"></i><b>11</b> Prior distributions</a><ul>
<li class="chapter" data-level="11.1" data-path="priors.html"><a href="priors.html#introduction-2"><i class="fa fa-check"></i><b>11.1</b> Introduction</a></li>
<li class="chapter" data-level="11.2" data-path="priors.html"><a href="priors.html#choosepriors"><i class="fa fa-check"></i><b>11.2</b> How to choose a prior</a></li>
<li class="chapter" data-level="11.3" data-path="priors.html"><a href="priors.html#prior-sensitivity"><i class="fa fa-check"></i><b>11.3</b> Prior sensitivity</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="stan.html"><a href="stan.html"><i class="fa fa-check"></i><b>12</b> MCMC using Stan</a><ul>
<li class="chapter" data-level="12.1" data-path="stan.html"><a href="stan.html#background"><i class="fa fa-check"></i><b>12.1</b> Background</a></li>
<li class="chapter" data-level="12.2" data-path="stan.html"><a href="stan.html#install-rstan"><i class="fa fa-check"></i><b>12.2</b> Install <code>rstan</code></a></li>
<li class="chapter" data-level="12.3" data-path="stan.html"><a href="stan.html#firststanmod"><i class="fa fa-check"></i><b>12.3</b> Writing a Stan model</a></li>
<li class="chapter" data-level="12.4" data-path="stan.html"><a href="stan.html#run-stan-from-r"><i class="fa fa-check"></i><b>12.4</b> Run Stan from R</a></li>
<li class="chapter" data-level="" data-path="stan.html"><a href="stan.html#further-reading-7"><i class="fa fa-check"></i>Further reading</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="ridge.html"><a href="ridge.html"><i class="fa fa-check"></i><b>13</b> Ridge regression</a><ul>
<li class="chapter" data-level="13.1" data-path="ridge.html"><a href="ridge.html#introduction-3"><i class="fa fa-check"></i><b>13.1</b> Introduction</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="sem.html"><a href="sem.html"><i class="fa fa-check"></i><b>14</b> Structural equation model</a><ul>
<li class="chapter" data-level="14.1" data-path="sem.html"><a href="sem.html#introduction-4"><i class="fa fa-check"></i><b>14.1</b> Introduction</a></li>
</ul></li>
<li class="part"><span><b>III ECOLOGICAL MODELS</b></span></li>
<li class="chapter" data-level="15" data-path="PART-III.html"><a href="PART-III.html"><i class="fa fa-check"></i><b>15</b> Introduction to PART III</a><ul>
<li class="chapter" data-level="15.1" data-path="PART-III.html"><a href="PART-III.html#model-notations"><i class="fa fa-check"></i><b>15.1</b> Model notations</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="zeroinflated-poisson-lmm.html"><a href="zeroinflated-poisson-lmm.html"><i class="fa fa-check"></i><b>16</b> Zero-inflated Poisson Mixed Model</a><ul>
<li class="chapter" data-level="16.1" data-path="zeroinflated-poisson-lmm.html"><a href="zeroinflated-poisson-lmm.html#introduction-5"><i class="fa fa-check"></i><b>16.1</b> Introduction</a></li>
<li class="chapter" data-level="16.2" data-path="zeroinflated-poisson-lmm.html"><a href="zeroinflated-poisson-lmm.html#example-data"><i class="fa fa-check"></i><b>16.2</b> Example data</a></li>
<li class="chapter" data-level="16.3" data-path="zeroinflated-poisson-lmm.html"><a href="zeroinflated-poisson-lmm.html#model"><i class="fa fa-check"></i><b>16.3</b> Model</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="cjs-with-mix.html"><a href="cjs-with-mix.html"><i class="fa fa-check"></i><b>17</b> Capture-mark recapture model with a mixture structure to account for missing sex-variable for parts of the individuals</a><ul>
<li class="chapter" data-level="17.1" data-path="cjs-with-mix.html"><a href="cjs-with-mix.html#introduction-6"><i class="fa fa-check"></i><b>17.1</b> Introduction</a></li>
<li class="chapter" data-level="17.2" data-path="cjs-with-mix.html"><a href="cjs-with-mix.html#data-description"><i class="fa fa-check"></i><b>17.2</b> Data description</a></li>
<li class="chapter" data-level="17.3" data-path="cjs-with-mix.html"><a href="cjs-with-mix.html#model-description"><i class="fa fa-check"></i><b>17.3</b> Model description</a></li>
<li class="chapter" data-level="17.4" data-path="cjs-with-mix.html"><a href="cjs-with-mix.html#the-stan-code"><i class="fa fa-check"></i><b>17.4</b> The Stan code</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="referenzen.html"><a href="referenzen.html"><i class="fa fa-check"></i>Referenzen</a></li>
<li class="divider"></li>
</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Analysis in Ecology with R and Stan</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="basics" class="section level1">
<h1><span class="header-section-number">2</span> Prerequisits: Basic statistical terms</h1>
<p>This chapter introduces some important terms useful for doing data analyses. It also introduces the essentials of the classical frequentist tests such as t- and Chisquare test. We will not use them later but we think it is important to know how to interpret the results in order to be able to understand 100 years of scientific literature. For each classical test, we provide a suggestion how to do it in a Bayesian way and we discuss some differences between the Bayesian and frequentist statistics.</p>
<div id="scale-of-measurement" class="section level2">
<h2><span class="header-section-number">2.1</span> Scale of measurement</h2>
<table style="width:99%;">
<colgroup>
<col width="12%" />
<col width="27%" />
<col width="27%" />
<col width="30%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Scale</th>
<th align="left">Examples</th>
<th align="left">Properties</th>
<th align="left">Coding in R</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Nominal</td>
<td align="left">Sex, genotype, habitat</td>
<td align="left">Identity (values have a unique meaning)</td>
<td align="left"><code>factor()</code></td>
</tr>
<tr class="even">
<td align="left">Ordinal</td>
<td align="left">Elevational zones</td>
<td align="left">Identity and magnitude (values have an ordered relationship)</td>
<td align="left"><code>ordered()</code></td>
</tr>
<tr class="odd">
<td align="left">Numeric</td>
<td align="left">Discrete: counts; continuous: body weight, wing length</td>
<td align="left">Identity, magnitude, and equal intervals</td>
<td align="left"><code>intgeger()</code> <code>numeric()</code></td>
</tr>
</tbody>
</table>
</div>
<div id="correlations" class="section level2">
<h2><span class="header-section-number">2.2</span> Correlations</h2>
<div id="basics-of-variances-covariances-and-correlations" class="section level3">
<h3><span class="header-section-number">2.2.1</span> Basics of variances, covariances and correlations</h3>
<ul>
<li><p>variance <span class="math inline">\(\hat{\sigma^2} = s^2 = \frac{1}{n-1}\sum_{i=1}^{n}(x_i-\bar{x})^2\)</span><br />
The term <span class="math inline">\((n-1)\)</span> is called the degrees of freedom.</p></li>
<li><p>standard deviation <span class="math inline">\(\hat{\sigma} = s = \sqrt{s^2}\)</span></p></li>
<li><p>covariance <span class="math inline">\(q = \frac{1}{n-1}\sum_{i=1}^{n}((x_i-\bar{x})*(y_i-\bar{y}))\)</span></p></li>
</ul>
</div>
<div id="pearson-correlation-coefficient" class="section level3">
<h3><span class="header-section-number">2.2.2</span> Pearson correlation coefficient</h3>
<p>standardized covariance</p>
<p><span class="math inline">\(r=\frac{\sum_{i=1}^{n}(x_i-\bar{x})(y_i-\bar{y})}{\sqrt{\sum_{i=1}^{n}(x_i-\bar{x})^2\sum_{i=1}^{n}(y_i-\bar{y})^2}}\)</span></p>
</div>
<div id="spearman-correlation-coefficient" class="section level3">
<h3><span class="header-section-number">2.2.3</span> Spearman correlation coefficient</h3>
<p>rank correlation<br />
correlation between rank(x) and rank(y)</p>
<p>robust against outliers</p>
</div>
<div id="kendalls-tau" class="section level3">
<h3><span class="header-section-number">2.2.4</span> Kendall’s tau</h3>
<p>rank correlation</p>
<p>I = number of pairs (i,k) for which <span class="math inline">\((x_i &lt; x_k)\)</span> &amp; <span class="math inline">\((y_i &gt; y_k)\)</span> or viceversa<br />
<span class="math inline">\(\tau = 1-\frac{4I}{(n(n-1))}\)</span></p>
</div>
</div>
<div id="principal-components-analyses-pca" class="section level2">
<h2><span class="header-section-number">2.3</span> Principal components analyses PCA</h2>
<p>rotation of the coordinate system</p>
<div class="figure"><span id="fig:unnamed-chunk-2"></span>
<img src="02-prerequisites_files/figure-html/unnamed-chunk-2-1.png" alt="Principal components are eigenvectors of the covariance or correlation matrix" width="768" />
<p class="caption">
Figure 2.1: Principal components are eigenvectors of the covariance or correlation matrix
</p>
</div>
<p>rotation of the coordinate system so that</p>
<ul>
<li>first component explains most variance<br />
</li>
<li>second component explains most of the remaining variance and is perpendicular to the first one<br />
</li>
<li>third component explains most of the remaining variance and is perpendicular to the first two<br />
</li>
<li>…</li>
</ul>
<p><span class="math inline">\((x,y)\)</span> becomes <span class="math inline">\((pc1, pc2)\)</span><br />
where<br />
<span class="math inline">\(pc1_i= b_{11} x_i + b_{12} y_i\)</span><br />
<span class="math inline">\(pc2_i = b_{21} x_i + b_{22} y_i\)</span> with <span class="math inline">\(b_{jk}\)</span> being loadings</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pca &lt;-<span class="st"> </span><span class="kw">princomp</span>(<span class="kw">cbind</span>(x,y), <span class="dt">cor=</span><span class="ot">TRUE</span>)
<span class="kw">loadings</span>(pca)</code></pre></div>
<pre><code>## 
## Loadings:
##   Comp.1 Comp.2
## x  0.707  0.707
## y  0.707 -0.707
## 
##                Comp.1 Comp.2
## SS loadings       1.0    1.0
## Proportion Var    0.5    0.5
## Cumulative Var    0.5    1.0</code></pre>
<p>loadings of a component can be multiplied by -1</p>
<p>proportion of variance explained by each component<br />
number of components = number of variables</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(pca)</code></pre></div>
<pre><code>## Importance of components:
##                           Comp.1    Comp.2
## Standard deviation     1.3017285 0.5527231
## Proportion of Variance 0.8472486 0.1527514
## Cumulative Proportion  0.8472486 1.0000000</code></pre>
<p>outlook: components with low variance are shrinked to a higher degree in Ridge regression</p>
<div id="inferential-statistics" class="section level3">
<h3><span class="header-section-number">2.3.1</span> Inferential statistics</h3>
<blockquote>
<p>there is never a “yes-or-no” answer<br />
there will always be uncertainty<br />
Amrhein (2017)[<a href="https://peerj.com/preprints/26857" class="uri">https://peerj.com/preprints/26857</a>]</p>
</blockquote>
<p>The decision whether an effect is important or not cannot not be done based on data alone. For a decision we should carefully consider the consequences of each decision, the aims we would like to achieve and the data. Consequences, needs and wishes of different stakeholders can be formally combined with the information in data by using methods of the decision theory. In most data analyses, particularly in basic research and when working on case studies, we normally do not consider consequences of decisions. In these cases, our job is extracting the information of data so that this information later can be used by other scientists, stakeholders and politicians to make decisions.</p>
<p>Therefore, statistics is describing pattern in data and quantifying the uncertainty of the described patterns that is due to the fact that the data is just a (small) random sample from the population we would like to know.</p>
<p>Quantification of uncertainty is only possible if</p>
<ol style="list-style-type: decimal">
<li>the mechanisms under study are known</li>
<li>the observations are a random sample from the population of interest</li>
</ol>
<p>Solutions:<br />
to 1. working with models and reporting assumptions<br />
to 2. study design</p>
<blockquote>
<p>reported uncertainties always are too small!</p>
</blockquote>
<p>Example: Number of stats courses before starting a PhD among all PhD students</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># simulate the virtual true population</span>
<span class="kw">set.seed</span>(<span class="dv">235325</span>)   <span class="co"># set seed for random number generator</span>

<span class="co"># simulate fake data of the whole population</span>
statscourses &lt;-<span class="st"> </span><span class="kw">rpois</span>(<span class="dv">300000</span>, <span class="kw">rgamma</span>(<span class="dv">300000</span>, <span class="dv">2</span>, <span class="dv">3</span>))  

<span class="co"># draw a random sample from the population</span>
n &lt;-<span class="st"> </span><span class="dv">12</span>            <span class="co"># sample size</span>
y &lt;-<span class="st"> </span><span class="kw">sample</span>(statscourses, <span class="dv">12</span>, <span class="dt">replace=</span><span class="ot">FALSE</span>)         </code></pre></div>
<p><img src="02-prerequisites_files/figure-html/unnamed-chunk-6-1.png" width="768" /></p>
<p>We observe the sample mean, what do we know about the population mean?</p>
<p>Frequentist solution: How would the sample mean scatter, if we repeat the study many times?</p>
<p>Bayesian solution: For any possible value, what is the probability that it is the true population mean?</p>
<p><img src="02-prerequisites_files/figure-html/unnamed-chunk-7-1.png" width="768" /></p>
</div>
</div>
<div id="standard-deviation-and-standard-error" class="section level2">
<h2><span class="header-section-number">2.4</span> Standard deviation and standard error</h2>
<p><img src="02-prerequisites_files/figure-html/unnamed-chunk-8-1.png" width="768" /></p>
<p>frequentist SE = SD/sqrt(n)</p>
<p>Bayesian SE = SD of posterior distribution</p>
</div>
<div id="central-limit-theorem-law-of-large-numbers" class="section level2">
<h2><span class="header-section-number">2.5</span> Central limit theorem / law of large numbers</h2>
<p><img src="02-prerequisites_files/figure-html/unnamed-chunk-9-1.png" width="768" /></p>
<p>normal distribution = Gaussian distribution</p>
<p><span class="math inline">\(p(\theta) = \frac{1}{\sqrt{2\pi}\sigma}exp(-\frac{1}{2\sigma^2}(\theta -\mu)^2) = Normal(\mu, \sigma)\)</span></p>
<p><span class="math inline">\(E(\theta) = \mu\)</span>, <span class="math inline">\(var(\theta) = \sigma^2\)</span>, <span class="math inline">\(mode(\theta) = \mu\)</span></p>
<p><img src="02-prerequisites_files/figure-html/unnamed-chunk-10-1.png" width="768" /></p>
</div>
<div id="bayes-theorem" class="section level2">
<h2><span class="header-section-number">2.6</span> Bayes theorem</h2>
<p><span class="math inline">\(P(A|B) = \frac{P(B|A)P(A)}{P(B)}\)</span></p>
<table>
<thead>
<tr class="header">
<th align="left">car</th>
<th align="left">flowers</th>
<th align="left">wine</th>
<th align="left"><strong>sum</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">no</td>
<td align="left">5</td>
<td align="left">3</td>
<td align="left"><strong>8</strong></td>
</tr>
<tr class="even">
<td align="left">yes</td>
<td align="left">1</td>
<td align="left">4</td>
<td align="left"><strong>5</strong></td>
</tr>
<tr class="odd">
<td align="left">——-</td>
<td align="left">—————-</td>
<td align="left">—————-</td>
<td align="left">——————-</td>
</tr>
<tr class="even">
<td align="left"><strong>sum</strong></td>
<td align="left"><strong>6</strong></td>
<td align="left"><strong>7</strong></td>
<td align="left"><strong>13</strong></td>
</tr>
</tbody>
</table>
<p>What is the probability that the person likes wine given it has no car?<br />
<span class="math inline">\(P(A) =\)</span> likes wine <span class="math inline">\(= 0.54\)</span><br />
<span class="math inline">\(P(B) =\)</span> no car <span class="math inline">\(= 0.62\)</span></p>
<p><span class="math inline">\(P(B|A) =\)</span> proportion car-free people among the wine liker <span class="math inline">\(= 0.43\)</span></p>
<p>Knowing whether a persons owns a car increases the knowledge of the birthday preference.</p>
</div>
<div id="bayes-theorem-for-continuous-parameters" class="section level2">
<h2><span class="header-section-number">2.7</span> Bayes theorem for continuous parameters</h2>
<p><span class="math inline">\(p(\theta|y) = \frac{p(y|\theta)p(\theta)}{p(y)} = \frac{p(y|\theta)p(\theta)}{\int p(y|\theta)p(\theta) d\theta}\)</span></p>
<p><span class="math inline">\(p(\theta|y)\)</span>: posterior distribution</p>
<p><span class="math inline">\(p(y|\theta)\)</span>: likelihood, data model</p>
<p><span class="math inline">\(p(\theta)\)</span>: prior distribution</p>
<p><span class="math inline">\(p(y)\)</span>: scaling constant</p>
</div>
<div id="single-parameter-model" class="section level2">
<h2><span class="header-section-number">2.8</span> Single parameter model</h2>
<p><span class="math inline">\(p(y|\theta) = Norm(\theta, \sigma)\)</span>, with <span class="math inline">\(\sigma\)</span> known</p>
<p><span class="math inline">\(p(\theta) = Norm(\mu_0, \tau_0)\)</span></p>
<p><span class="math inline">\(p(\theta|y) = Norm(\mu_n, \tau_n)\)</span>, where <span class="math inline">\(\mu_n= \frac{\frac{1}{\tau_0^2}\mu_0 + \frac{n}{\sigma^2}\bar{y}}{\frac{1}{\tau_0^2}+\frac{n}{\sigma^2}}\)</span> and <span class="math inline">\(\frac{1}{\tau_n^2} = \frac{1}{\tau_0^2} + \frac{n}{\sigma^2}\)</span></p>
<p><span class="math inline">\(\bar{y}\)</span> is a sufficient statistics<br />
<span class="math inline">\(p(\theta) = Norm(\mu_0, \tau_0)\)</span> is a conjugate prior for <span class="math inline">\(p(y|\theta) = Norm(\theta, \sigma)\)</span>, with <span class="math inline">\(\sigma\)</span> known.</p>
<p>Posterior mean = weighted average between prior mean and <span class="math inline">\(\bar{y}\)</span> with weights equal to the precisions (<span class="math inline">\(\frac{1}{\tau_0^2}\)</span> and <span class="math inline">\(\frac{n}{\sigma^2}\)</span>) <img src="02-prerequisites_files/figure-html/unnamed-chunk-12-1.png" width="5600" /></p>
</div>
<div id="a-model-with-two-parameters" class="section level2">
<h2><span class="header-section-number">2.9</span> A model with two parameters</h2>
<p><span class="math inline">\(p(y|\theta, \sigma) = Norm(\theta, \sigma)\)</span></p>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># weight (g)</span>
y &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">47.5</span>, <span class="dv">43</span>, <span class="dv">43</span>, <span class="dv">44</span>, <span class="fl">48.5</span>, <span class="fl">37.5</span>, <span class="fl">41.5</span>, <span class="fl">45.5</span>)
n &lt;-<span class="st"> </span><span class="kw">length</span>(y)</code></pre></div>
<p><span class="math inline">\(p(y|\theta, \sigma) = Norm(\theta, \sigma)\)</span></p>
<p><span class="math inline">\(p(\theta, \sigma) = N-Inv-\chi^2(\mu_0, \sigma_0^2/\kappa_0; v_0, \sigma_0^2)\)</span> conjugate prior</p>
<p><span class="math inline">\(p(\theta,\sigma|y) = \frac{p(y|\theta, \sigma)p(\theta, \sigma)}{p(y)} = N-Inv-\chi^2(\mu_n, \sigma_n^2/\kappa_n; v_n, \sigma_n^2)\)</span>, with</p>
<p><span class="math inline">\(\mu_n= \frac{\kappa_0}{\kappa_0+n}\mu_0 + \frac{n}{\kappa_0+n}\bar{y}\)</span></p>
<p><span class="math inline">\(\kappa_n = \kappa_0+n\)</span></p>
<p><span class="math inline">\(v_n = v_0 +n\)</span></p>
<p><span class="math inline">\(v_n\sigma_n^2=v_0\sigma_0^2+(n-1)s^2+\frac{\kappa_0n}{\kappa_0+n}(\bar{y}-\mu_0)^2\)</span></p>
<p><span class="math inline">\(\bar{y}\)</span> and <span class="math inline">\(s^2\)</span> are sufficient statistics</p>
<p>Joint, marginal and conditional posterior distributions <img src="02-prerequisites_files/figure-html/unnamed-chunk-14-1.png" width="768" /></p>
</div>
<div id="t-distribution" class="section level2">
<h2><span class="header-section-number">2.10</span> t-distribution</h2>
<p>marginal posterior distribution of a normal mean with unknown variance and conjugate prior distribution</p>
<p><span class="math inline">\(p(\theta|v,\mu,\sigma) = \frac{\Gamma((v+1)/2)}{\Gamma(v/2)\sqrt{v\pi}\sigma}(1+\frac{1}{v}(\frac{\theta-\mu}{\sigma})^2)^{-(v+1)/2}\)</span></p>
<p><span class="math inline">\(v\)</span> degrees of freedom<br />
<span class="math inline">\(\mu\)</span> location<br />
<span class="math inline">\(\sigma\)</span> scale</p>
</div>
<div id="frequentist-one-sample-t-test" class="section level2">
<h2><span class="header-section-number">2.11</span> Frequentist one-sample t-test</h2>
<p>H0: the mean weight is equal to exactly 40g.</p>
<p><span class="math inline">\(t = \frac{\bar{y}-\mu_0}{\frac{s}{\sqrt{n}}}\)</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(y, <span class="dt">mu=</span><span class="dv">40</span>)</code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  y
## t = 3.0951, df = 7, p-value = 0.01744
## alternative hypothesis: true mean is not equal to 40
## 95 percent confidence interval:
##  40.89979 46.72521
## sample estimates:
## mean of x 
##   43.8125</code></pre>
</div>
<div id="nullhypothesis-test" class="section level2">
<h2><span class="header-section-number">2.12</span> Nullhypothesis test</h2>
<p>p-value: Probability of the data or more extreme data given the null hypothesis is true.</p>
<p><img src="02-prerequisites_files/figure-html/unnamed-chunk-16-1.png" width="768" style="display: block; margin: auto;" /></p>
</div>
<div id="confidence-interval" class="section level2">
<h2><span class="header-section-number">2.13</span> Confidence interval</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># lower limit of 95% CI</span>
<span class="kw">mean</span>(y) <span class="op">+</span><span class="st"> </span><span class="kw">qt</span>(<span class="fl">0.025</span>, <span class="dt">df=</span><span class="dv">7</span>)<span class="op">*</span><span class="kw">sd</span>(y)<span class="op">/</span><span class="kw">sqrt</span>(n) 
<span class="co"># upper limit of 95% CI</span>
<span class="kw">mean</span>(y) <span class="op">+</span><span class="st"> </span><span class="kw">qt</span>(<span class="fl">0.975</span>, <span class="dt">df=</span><span class="dv">7</span>)<span class="op">*</span><span class="kw">sd</span>(y)<span class="op">/</span><span class="kw">sqrt</span>(n) </code></pre></div>
<p><img src="02-prerequisites_files/figure-html/unnamed-chunk-18-1.png" width="576" style="display: block; margin: auto;" /></p>
</div>
<div id="posterior-distribution" class="section level2">
<h2><span class="header-section-number">2.14</span> Posterior distribution</h2>
<p><img src="02-prerequisites_files/figure-html/unnamed-chunk-19-1.png" width="768" /></p>
<p>Two different theories - one single result!</p>
</div>
<div id="posterior-probability" class="section level2">
<h2><span class="header-section-number">2.15</span> Posterior probability</h2>
<p>Probability <span class="math inline">\(P(H:\mu&lt;=40) =\)</span> 0.01 <img src="02-prerequisites_files/figure-html/unnamed-chunk-20-1.png" width="768" style="display: block; margin: auto;" /></p>
</div>
<div id="monte-carlo-simulation-parametric-bootstrap" class="section level2">
<h2><span class="header-section-number">2.16</span> Monte Carlo simulation (parametric bootstrap)</h2>
<p>Monte Carlo integration: numerical solution of <span class="math inline">\(\int_{-1}^{1.5} F(x) dx\)</span> <img src="02-prerequisites_files/figure-html/unnamed-chunk-21-1.png" width="768" /></p>
<p>sim is solving a mathematical problem by simulation How sim is simulating to get the marginal distribution of <span class="math inline">\(\mu\)</span>:</p>
<p><img src="02-prerequisites_files/figure-html/unnamed-chunk-22-1.png" width="768" /></p>
</div>
<div id="methods-for-getting-the-posterior-distribution" class="section level2">
<h2><span class="header-section-number">2.17</span> 3 methods for getting the posterior distribution</h2>
<ul>
<li>analytically</li>
<li>approximation</li>
<li>Monte Carlo simulation</li>
</ul>
</div>
<div id="grid-approximation" class="section level2">
<h2><span class="header-section-number">2.18</span> Grid approximation</h2>
<p><span class="math inline">\(p(\theta|y) = \frac{p(y|\theta)p(\theta)}{p(y)}\)</span></p>
<p>For example, one coin flip (Bernoulli model)</p>
<p>data: y=0 (a tail)<br />
likelihood: <span class="math inline">\(p(y|\theta)=\theta^y(1-\theta)^{(1-y)}\)</span></p>
<p><img src="02-prerequisites_files/figure-html/unnamed-chunk-23-1.png" width="768" /></p>
</div>
<div id="monte-carlo-simulations" class="section level2">
<h2><span class="header-section-number">2.19</span> Monte Carlo simulations</h2>
<ul>
<li>Markov chain Monte Carlo simulation (BUGS, Jags)</li>
<li>Hamiltonian Monte Carlo (Stan)</li>
</ul>
<p><img src="02-prerequisites_files/figure-html/unnamed-chunk-24-1.png" width="768" /></p>
</div>
<div id="comparison-of-the-locations-between-two-groups" class="section level2">
<h2><span class="header-section-number">2.20</span> Comparison of the locations between two groups</h2>
<p>Boxplot:<br />
Median, 50% box, extremes observation within 1.5 times the interquartile range, outliers</p>
<p>The uncertainties of the means do not show the uncertainty of the difference between the means!</p>
<p><img src="02-prerequisites_files/figure-html/unnamed-chunk-25-1.png" width="768" /></p>
</div>
<div id="difference-between-two-means" class="section level2">
<h2><span class="header-section-number">2.21</span> Difference between two means</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod &lt;-<span class="st"> </span><span class="kw">lm</span>(ell<span class="op">~</span>birthday, <span class="dt">data=</span>dat)
mod</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = ell ~ birthday, data = dat)
## 
## Coefficients:
##  (Intercept)  birthdaywine  
##      43.3333        0.6667</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">bsim &lt;-<span class="st"> </span><span class="kw">sim</span>(mod, <span class="dt">n.sim=</span>nsim)
<span class="kw">quantile</span>(bsim<span class="op">@</span>coef[,<span class="dv">2</span>], <span class="dt">prob=</span><span class="kw">c</span>(<span class="fl">0.025</span>, <span class="fl">0.5</span>, <span class="fl">0.975</span>))</code></pre></div>
<pre><code>##       2.5%        50%      97.5% 
## -1.6524462  0.6698085  2.9975599</code></pre>
</div>
<div id="two-sample-t-test" class="section level2">
<h2><span class="header-section-number">2.22</span> Two-sample t-test</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(ell<span class="op">~</span>birthday, <span class="dt">data=</span>dat, <span class="dt">var.equal=</span><span class="ot">TRUE</span>)</code></pre></div>
<pre><code>## 
##  Two Sample t-test
## 
## data:  ell by birthday
## t = -0.63369, df = 11, p-value = 0.5392
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -2.982185  1.648851
## sample estimates:
## mean in group flowers    mean in group wine 
##              43.33333              44.00000</code></pre>
</div>
<div id="wilxocon-test" class="section level2">
<h2><span class="header-section-number">2.23</span> Wilxocon test</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">wilcox.test</span>(ell<span class="op">~</span>birthday, <span class="dt">data=</span>dat)</code></pre></div>
<pre><code>## 
##  Wilcoxon rank sum test with continuity correction
## 
## data:  ell by birthday
## W = 18, p-value = 0.7172
## alternative hypothesis: true location shift is not equal to 0</code></pre>
</div>
<div id="randomisation-test" class="section level2">
<h2><span class="header-section-number">2.24</span> Randomisation test</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">diffH0 &lt;-<span class="st"> </span><span class="kw">numeric</span>(nsim)
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>nsim){
  randbirthday &lt;-<span class="st"> </span><span class="kw">sample</span>(dat<span class="op">$</span>birthday)
  rmod &lt;-<span class="st"> </span><span class="kw">lm</span>(ell<span class="op">~</span>randbirthday, <span class="dt">data=</span>dat)
  diffH0[i] &lt;-<span class="st"> </span><span class="kw">coef</span>(rmod)[<span class="dv">2</span>]
}
<span class="kw">mean</span>(<span class="kw">abs</span>(diffH0)<span class="op">&gt;</span><span class="kw">abs</span>(<span class="kw">coef</span>(mod)[<span class="dv">2</span>])) <span class="co"># p-value</span></code></pre></div>
<pre><code>## [1] 0.4898</code></pre>
<p><img src="02-prerequisites_files/figure-html/unnamed-chunk-30-1.png" width="768" /></p>
<ul>
<li>Produces the distribution of a test statistics given the null hypothesis.<br />
</li>
<li>assumption: all observations are independent<br />
</li>
<li>becomes unfeasible when data is structured</li>
</ul>
</div>
<div id="bootstrap" class="section level2">
<h2><span class="header-section-number">2.25</span> Bootstrap</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">diffboot &lt;-<span class="st"> </span><span class="kw">numeric</span>(nsim)
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>nsim){
  nbirthday &lt;-<span class="st"> </span><span class="dv">1</span>
  <span class="cf">while</span>(nbirthday<span class="op">==</span><span class="dv">1</span>){
    bootrows &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(dat), <span class="dt">replace=</span><span class="ot">TRUE</span>)
    nbirthday &lt;-<span class="st"> </span><span class="kw">length</span>(<span class="kw">unique</span>(dat<span class="op">$</span>birthday[bootrows]))
  }
  rmod &lt;-<span class="st"> </span><span class="kw">lm</span>(ell<span class="op">~</span>birthday, <span class="dt">data=</span>dat[bootrows,])
  diffboot[i] &lt;-<span class="st"> </span><span class="kw">coef</span>(rmod)[<span class="dv">2</span>]
}
<span class="kw">quantile</span>(diffboot, <span class="dt">prob=</span><span class="kw">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</code></pre></div>
<pre><code>##      2.5%     97.5% 
## -1.214286  2.725327</code></pre>
<ul>
<li>result is a confidence interval<br />
</li>
<li>assumption: all observations are independent!</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">hist</span>(diffboot); <span class="kw">abline</span>(<span class="dt">v=</span><span class="kw">coef</span>(mod)[<span class="dv">2</span>], <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</code></pre></div>
<p><img src="02-prerequisites_files/figure-html/unnamed-chunk-32-1.png" width="768" /></p>
</div>
<div id="f-distribution" class="section level2">
<h2><span class="header-section-number">2.26</span> F-distribution</h2>
<p>Ratios of sample variances drawn from populations with equal variances follow an F-distribution. The density function of the F-distribution is even more complicated than the one of the t-distribution! We do not copy it here. Further, we have not yet met any Bayesian example where the F-distribution is used (that does not mean that there is no). It is used in frequentist analyses in order to compare variances, and, within the ANOVA, to compare means between groups. If two variances only differ because of natural variance in the data (nullhypothesis) then <span class="math inline">\(\frac{Var(X_1)}{Var(X_2)}\sim F_{df_1,df_2}\)</span>.</p>
<div class="figure"><span id="fig:unnamed-chunk-33"></span>
<img src="02-prerequisites_files/figure-html/unnamed-chunk-33-1.png" alt="Different density functions of the F statistics" width="768" />
<p class="caption">
Figure 2.2: Different density functions of the F statistics
</p>
</div>
<div id="analysis-of-variance-anova" class="section level3">
<h3><span class="header-section-number">2.26.1</span> Analysis of variance ANOVA</h3>
<p>The aim of an ANOVA is to compare means of groups. In a frequentist analysis, this is done by comparing the between-group with the within-group variance. The result of a Bayesian analysis is the joint posterior distribution of the group means.</p>
<div class="figure"><span id="fig:unnamed-chunk-34"></span>
<img src="02-prerequisites_files/figure-html/unnamed-chunk-34-1.png" alt="Number of stats courses students have taken before starting a PhD in relation to their feeling about statistics." width="768" />
<p class="caption">
Figure 2.3: Number of stats courses students have taken before starting a PhD in relation to their feeling about statistics.
</p>
</div>
<p>In the frequentist ANOVA, the following three sum of squared distances (SS) are used to calculate the total, the between- and within-group variances:<br />
Total sum of squares = SST = <span class="math inline">\(\sum_1^n{(y_i-\bar{y})^2}\)</span><br />
Within-group SS = SSW = <span class="math inline">\(\sum_1^n{(y_i-\bar{y_g})^2}\)</span>: unexplained variance<br />
Between-group SS = SSB = <span class="math inline">\(\sum_1^g{n_g(\bar{y_g}-\bar{y})^2}\)</span>: explained variance</p>
<p>The between-group and within-group SS sum to the total sum of squares: SST=SSB+SSW. Attention: this equation is only true in any case for a simple one-way ANOVA (just one grouping factor). If the data are grouped according to more than one factor (such as in a two- or three-way ANOVA), then there is one single solution for the equation only when the data is completely balanced, i.e. when there are the same number of observations in all combinations of factor levels. For non-balanced data with more than one grouping factor, there are different ways of calculating the SSBs, and the result of the F-test described below depends on the order of the predictors in the model.</p>
<div class="figure"><span id="fig:unnamed-chunk-35"></span>
<img src="02-prerequisites_files/figure-html/unnamed-chunk-35-1.png" alt="Visualisation of the total, between-group and within-group sum of squares. Points are observations; long horizontal line is the overall mean; short horizontal lines are group specific means." width="768" />
<p class="caption">
Figure 2.4: Visualisation of the total, between-group and within-group sum of squares. Points are observations; long horizontal line is the overall mean; short horizontal lines are group specific means.
</p>
</div>
<p>In order to make SSB and SSW comparable, we have to divide them by their degrees of freedoms. For the within-group SS, SSW, the degrees of freedom is the number of obervations minus the number of groups (<span class="math inline">\(g\)</span>), because <span class="math inline">\(g\)</span> means have been estimated from the data. If the <span class="math inline">\(g\)</span> means are fixed and <span class="math inline">\(n-g\)</span> data points are known, then the last <span class="math inline">\(g\)</span> data points are defined, i.e., they cannot be chosen freely. For the between-group SS, SSB, the degrees of freedom is the number of groups minus 1 (the minus 1 stands for the overall mean).</p>
<ul>
<li>MSB = SSB/df_between, MSW = SSW/df_within</li>
</ul>
<p>It can be shown (by mathematicians) that, given the nullhypothesis, the mean of all groups are equal <span class="math inline">\(m_1 = m_2 = m_3\)</span>, then the mean squared errors between groups (MSB) is expected to be equal to the mean squared errors within the groups (MSW). Therefore, the ration MSB/MSW is expected to follow an F-distribution given the nullhypothesis is true.</p>
<ul>
<li>MSB/MSW ~ F(df_between, df_within)</li>
</ul>
<p>The Bayesian analysis for comparing group means consists of calculating the posterior distribution for each group mean and then drawing inference from these posterior distributions. A Bayesian one-way ANOVA involves the following steps:<br />
1. Decide for a data model: We, here, assume that the measurements are normally distributed around the group means. In this example here, we transform the outcome variable in order to better meet the normal assumption. Note: the frequentist ANOVA makes exactly the same assumptions. We can write the data model: <span class="math inline">\(y_i\sim Norm(\mu_i,\sigma)\)</span> with <span class="math inline">\(mu_i= \beta_0 + \beta_1I(group=2) +\beta_1I(group=3)\)</span>, where the <span class="math inline">\(I()\)</span>-function is an indicator function taking on 1 if the expression is true and 0 otherwise. This model has 4 parameters: <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span>, <span class="math inline">\(\beta_2\)</span> and <span class="math inline">\(\sigma\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># fit a normal model with 3 different means</span>
mod &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">log</span>(nrcourses<span class="op">+</span><span class="dv">1</span>)<span class="op">~</span>statsfeeling, <span class="dt">data=</span>dat)</code></pre></div>
<ol start="2" style="list-style-type: decimal">
<li><p>Choose a prior distribution for each model parameter: In this example, we choose flat prior distributions for each parameter. By using these priors, the result should not remarkably be affected by the prior distributions but almost only reflect the information in the data. We choose so-called improper prior distributions. These are completely flat distributions that give all parameter values the same probability. Such distributions are called improper because the area under the curve is not summing to 1 and therefore, they cannot be considered to be proper probability distributions. However, they can still be used to solve the Bayesian theorem.</p></li>
<li><p>Solve the Bayes theorem: The solution of the Bayes theorem for the above priors and model is implemented in the function sim of the package arm.</p></li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># calculate numerically the posterior distributions of the model </span>
<span class="co"># parameters using flat prior distributions</span>
nsim &lt;-<span class="st"> </span><span class="dv">5000</span>
<span class="kw">set.seed</span>(<span class="dv">346346</span>)
bsim &lt;-<span class="st"> </span><span class="kw">sim</span>(mod, <span class="dt">n.sim=</span>nsim)</code></pre></div>
<ol start="4" style="list-style-type: decimal">
<li>Display the joint posterior distributions of the group means</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># calculate group means from the model parameters</span>
newdat &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">statsfeeling=</span><span class="kw">levels</span>(dat<span class="op">$</span>statsfeeling))
X &lt;-<span class="st"> </span><span class="kw">model.matrix</span>(<span class="op">~</span>statsfeeling, <span class="dt">data=</span>newdat)
fitmat &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dt">ncol=</span>nsim, <span class="dt">nrow=</span><span class="kw">nrow</span>(newdat))
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>nsim) fitmat[,i] &lt;-<span class="st"> </span>X<span class="op">%*%</span>bsim<span class="op">@</span>coef[i,]
<span class="kw">hist</span>(fitmat[<span class="dv">1</span>,], <span class="dt">freq=</span><span class="ot">FALSE</span>, <span class="dt">breaks=</span><span class="kw">seq</span>(<span class="op">-</span><span class="fl">2.5</span>, <span class="fl">4.2</span>, <span class="dt">by=</span><span class="fl">0.1</span>), <span class="dt">main=</span><span class="ot">NA</span>, <span class="dt">xlab=</span><span class="st">&quot;Group mean of log(number of courses +1)&quot;</span>, <span class="dt">las=</span><span class="dv">1</span>, <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">2.2</span>))
<span class="kw">hist</span>(fitmat[<span class="dv">2</span>,], <span class="dt">freq=</span><span class="ot">FALSE</span>, <span class="dt">breaks=</span><span class="kw">seq</span>(<span class="op">-</span><span class="fl">2.5</span>, <span class="fl">4.2</span>, <span class="dt">by=</span><span class="fl">0.1</span>), <span class="dt">main=</span><span class="ot">NA</span>, <span class="dt">xlab=</span><span class="st">&quot;&quot;</span>, <span class="dt">las=</span><span class="dv">1</span>, <span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">col=</span><span class="kw">rgb</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="fl">0.5</span>))
<span class="kw">hist</span>(fitmat[<span class="dv">3</span>,], <span class="dt">freq=</span><span class="ot">FALSE</span>, <span class="dt">breaks=</span><span class="kw">seq</span>(<span class="op">-</span><span class="fl">2.5</span>, <span class="fl">4.2</span>, <span class="dt">by=</span><span class="fl">0.1</span>), <span class="dt">main=</span><span class="ot">NA</span>, <span class="dt">xlab=</span><span class="st">&quot;&quot;</span>, <span class="dt">las=</span><span class="dv">1</span>, <span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">col=</span><span class="kw">rgb</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="fl">0.5</span>))
<span class="kw">legend</span>(<span class="dv">2</span>,<span class="dv">2</span>, <span class="dt">fill=</span><span class="kw">c</span>(<span class="st">&quot;white&quot;</span>,<span class="kw">rgb</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="fl">0.5</span>), <span class="kw">rgb</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="fl">0.5</span>)), <span class="dt">legend=</span><span class="kw">levels</span>(dat<span class="op">$</span>statsfeeling))</code></pre></div>
<div class="figure"><span id="fig:unnamed-chunk-38"></span>
<img src="02-prerequisites_files/figure-html/unnamed-chunk-38-1.png" alt="Posterior distributions of the mean number of stats courses PhD students visited before starting the PhD grouped according to their feelings about statistics." width="768" />
<p class="caption">
Figure 2.5: Posterior distributions of the mean number of stats courses PhD students visited before starting the PhD grouped according to their feelings about statistics.
</p>
</div>
<p>Based on the posterior distributions of the group means, we can extract derived quantities depending on our interest and questions. Here, for example, we could extract the posterior probability of the hypothesis that students with a positive feeling about statistics have a better education in statistics than those with a neutral or negative feeling about statistics.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># P(mean(positive)&gt;mean(neutral))</span>
<span class="kw">mean</span>(fitmat[<span class="dv">3</span>,]<span class="op">&gt;</span>fitmat[<span class="dv">2</span>,])</code></pre></div>
<pre><code>## [1] 0.9004</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># P(mean(positive)&gt;mean(negative))</span>
<span class="kw">mean</span>(fitmat[<span class="dv">3</span>,]<span class="op">&gt;</span>fitmat[<span class="dv">1</span>,])</code></pre></div>
<pre><code>## [1] 0.953</code></pre>
</div>
</div>
<div id="chisquare-test" class="section level2">
<h2><span class="header-section-number">2.27</span> Chisquare test</h2>
<p>The chisquare test is used for two frequentist purposes.<br />
1. Testing for correlations between two categorical variables.<br />
2. Comparison of two distributions (goodness of fit test)</p>
<p>When testing for correlations between two categorical variables, then the nullhypothesis is “there is no correlation”. The data can be displayed in cross-tables.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Example: correlation between birthday preference and car ownership</span>
<span class="kw">table</span>(dat<span class="op">$</span>birthday, dat<span class="op">$</span>car)</code></pre></div>
<pre><code>##          
##           N Y
##   flowers 5 1
##   wine    3 4</code></pre>
<p>Given the nullhypothesis is true, we expect that the distribution of the data in each column of the cross-table is similar to the distribution of the row-sums. And, the distribution of the data in each row should be similar to the distribution of the column-sums. The chisquare test statistics <span class="math inline">\(\chi^2\)</span> measures the deviation of the data from this expected distribution of the data in the cross-table.</p>
<p>For calculating the chisquare test statistics <span class="math inline">\(\chi^2\)</span>, we first have to obtain for each cell in the cross-table the expected value <span class="math inline">\(E_{ij}\)</span> = rowsum*colsum/total.</p>
<p><span class="math inline">\(\chi^2\)</span> measures the difference between the observed <span class="math inline">\(O_{ij}\)</span> and expected <span class="math inline">\(E_{ij}\)</span> values as:<br />
<span class="math inline">\(\chi^2=\sum_{i=1}^{m}\sum_{j=1}^{k}\frac{(O_{ij}-E_{ij})^2}{E_{ij}}\)</span> where <span class="math inline">\(m\)</span> is the number of rows and <span class="math inline">\(k\)</span> is the number of columns. The <span class="math inline">\(\chi^2\)</span>-distribution has 1 parameter, the degrees of freedom <span class="math inline">\(v\)</span> = <span class="math inline">\((m-1)(k-1)\)</span>.</p>
<p><img src="02-prerequisites_files/figure-html/unnamed-chunk-41-1.png" width="672" /></p>
<p>R is calculating the <span class="math inline">\(\chi^2\)</span> value for specific cross-tables, and it is also giving the p-values, i.e., the probability of obtaining the observed or a higher <span class="math inline">\(\chi^2\)</span> value given the nullhypothesis is true by comparing the observed <span class="math inline">\(\chi^2\)</span> with the corresponding chisquare distribution.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">chisq.test</span>(<span class="kw">table</span>(dat<span class="op">$</span>birthday, dat<span class="op">$</span>car))</code></pre></div>
<pre><code>## 
##  Pearson&#39;s Chi-squared test with Yates&#39; continuity correction
## 
## data:  table(dat$birthday, dat$car)
## X-squared = 0.85312, df = 1, p-value = 0.3557</code></pre>
<p>The warning (that is suppressed in the rmarkdown version, but that you will see if you run the code on your own computer) is given, because in our example some cells have counts less than 5. In such cases, the Fisher’s exact test should be preferred. This test calculates the p-value analytically using probability theory, whereas the chisquare test relies on the assumption that the <span class="math inline">\(\chi^2\)</span> value follows a chisquare distribution. The latter assumption holds better for larger sample sizes.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">fisher.test</span>(<span class="kw">table</span>(dat<span class="op">$</span>birthday, dat<span class="op">$</span>car))</code></pre></div>
<pre><code>## 
##  Fisher&#39;s Exact Test for Count Data
## 
## data:  table(dat$birthday, dat$car)
## p-value = 0.2657
## alternative hypothesis: true odds ratio is not equal to 1
## 95 percent confidence interval:
##    0.3369761 391.2320030
## sample estimates:
## odds ratio 
##   5.699654</code></pre>
</div>
<div id="bayesian-way-of-analysing-correlations-between-categorical-variables" class="section level2">
<h2><span class="header-section-number">2.28</span> Bayesian way of analysing correlations between categorical variables</h2>
<p>For a Bayesian analysis of cross-table data, a data model has to be found. There are several possibilities that could be used:</p>
<ul>
<li>a so-called log-linear model (Poisson model) for the counts in each cell of the cross-table.<br />
</li>
<li>a binomial or a multinomial model for obtaining estimates of the proportions of data in each cell</li>
</ul>
<p>These models provide possibilities to explore the patterns in the data in more details than a chisquare test.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># log-linear model</span>
mod &lt;-<span class="st"> </span><span class="kw">glm</span>(count<span class="op">~</span>birthday<span class="op">+</span>car <span class="op">+</span><span class="st"> </span>birthday<span class="op">:</span>car, 
           <span class="dt">data=</span>datagg, <span class="dt">family=</span>poisson)
bsim &lt;-<span class="st"> </span><span class="kw">sim</span>(mod, <span class="dt">n.sim=</span>nsim)
<span class="kw">round</span>(<span class="kw">t</span>(<span class="kw">apply</span>(bsim<span class="op">@</span>coef, <span class="dv">2</span>, quantile, 
              <span class="dt">prob=</span><span class="kw">c</span>(<span class="fl">0.025</span>, <span class="fl">0.5</span>, <span class="fl">0.975</span>))),<span class="dv">2</span>)</code></pre></div>
<pre><code>##                    2.5%   50% 97.5%
## (Intercept)        0.74  1.61  2.47
## birthdaywine      -1.91 -0.50  0.90
## carY              -3.71 -1.62  0.52
## birthdaywine:carY -0.67  1.88  4.40</code></pre>
<p>The interaction parameter measures the strength of the correlation. To quantitatively understand what a parameter value of 1.90 means, we have to look at the interpretation of all parameter values. We do that here quickly without a thorough explanation, because we already explained the Poisson model in chapter 8 of <span class="citation">(F. Korner-Nievergelt et al. <a href="referenzen.html#ref-KornerNievergelt2015">2015</a>)</span>.</p>
<p>The intercept 1.61 corresponds to the logarithm of the count in the cell “flowers” and “N” (number of students who prefer flowers as a birthday present and who do not have a car), i.e., <span class="math inline">\(exp(\beta_0)\)</span> = 5.00. The exponent of the second parameter corresponds to the multiplicative difference between the counts in the cells “flowers and N” and “wine and N”, i.e., count in the cell “wine and N” = <span class="math inline">\(exp(\beta_0)exp(\beta_1)\)</span> = exp(1.61)exp(-0.51) = 3.00. The third parameter measures the multiplicative difference in the counts between the cells “flowers and N” and “flowers and Y”, i.e., count in the cell “flowers and Y” = <span class="math inline">\(exp(\beta_0)exp(\beta_2)\)</span> = exp(1.61)exp(-1.61) = 1.00. Thus, the third parameter is the difference in the logarithm of the counts between the car owners and the car-free students for those who prefer flowers. The interaction parameter is the difference of this difference between the students who prefer wine and those who prefer flowers. This is difficult to intuitively understand. Here is another try to formulate it: The interaction parameter measures the difference in the logarithm of the counts in the cross-table between the row-differences between the columns. Maybe it becomes clear, when we extract the count in the cell “wine and Y” from the model parameters: <span class="math inline">\(exp(\beta_0)exp(\beta_1)exp(\beta_2)exp(\beta_3)\)</span> = exp(1.61)exp(-0.51)exp(-1.61)exp(1.90) = 4.00.</p>
<p>Alternatively, we could estimate the proportions of flower and wine preferers within each group of car owners and car-free students using a binomial model. For an explanation of the binomial model, see chapter 8 of <span class="citation">(F. Korner-Nievergelt et al. <a href="referenzen.html#ref-KornerNievergelt2015">2015</a>)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># binomial model</span>
tab &lt;-<span class="st"> </span><span class="kw">table</span>(dat<span class="op">$</span>car,dat<span class="op">$</span>birthday)
mod &lt;-<span class="st"> </span><span class="kw">glm</span>(tab<span class="op">~</span><span class="kw">rownames</span>(tab),  <span class="dt">family=</span>binomial)
bsim &lt;-<span class="st"> </span><span class="kw">sim</span>(mod, <span class="dt">n.sim=</span>nsim)</code></pre></div>
<div class="figure"><span id="fig:unnamed-chunk-47"></span>
<img src="02-prerequisites_files/figure-html/unnamed-chunk-47-1.png" alt="Estimated proportion of students that prefer flowers over wine as a birthday present among the car-free students (N) and the car owners (Y). Given are the median of the posterior distribution (circle). The bar extends between the 2.5% and 97.5% quantiles of the posterior distribution." width="768" />
<p class="caption">
Figure 2.6: Estimated proportion of students that prefer flowers over wine as a birthday present among the car-free students (N) and the car owners (Y). Given are the median of the posterior distribution (circle). The bar extends between the 2.5% and 97.5% quantiles of the posterior distribution.
</p>
</div>
</div>
<div id="summary" class="section level2">
<h2><span class="header-section-number">2.29</span> Summary</h2>
<p>Bayesian data analysis = applying the Bayes theorem for summarising knowledge based on data, priors and the model assumptions.</p>
<p>Frequentist statistics = quantifying uncertainty by hypothetical repetitions</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="PART-I.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="analyses-steps.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/TobiasRoth/BDAEcology/edit/master/02-prerequisites.Rmd",
"text": "Edit"
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
