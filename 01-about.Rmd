# Why do we Need Statistical Models and What is this Book About? {#about}


## WHY WE NEED STATISTICAL MODELS
There are at least four main reasons why statistical models are used: (1) models help to describe how we think a system works, (2) data can be summarized using models, (3) comparison of model predictions with data helps with understanding the system, and (4) models allow for predictions, including the quantification of their uncertainty, and, therefore, they help with making decisions.

A statistical model is a mathematical construct based on probability theory that aims to reconstruct the system or the process under study; the data are observations of this system or process. When we speak of “models” in this book, we always mean statistical models. Models express what we know (or, better, what we think we know) about a natural system. The difference between the model and the observations shows that what we think about the system may still not be realistic and, therefore, points out what we may want to think about more intensively. In this way, statistical models help with understanding natural systems.

Analyzing data using statistical models is rarely just applying one model to the data and extracting the results. Rather, it is an iterative process of fitting a model, comparing the model with the data, gaining insight into the system from specific discrepancies between the model and the data, and then finding a more realistic model. Analyzing data using statistical models is a learning process. Reality is usually too complex to be perfectly represented by a model. Thus, no model is perfect, but a good model is useful (e.g., Box, 1979). Often, several models may be plausible and fit the data reasonably well. In such cases, the inference can be based on the set of all models, or a model that performs best for a specific purpose is selected. In Chapter 11 we have compiled a number of approaches we found useful for model comparisons and multimodel inference. 

Once we have one or several models, we want to draw inferences from the model(s). Estimates of the effects of the predictor variables on the outcome variables, fitted values, or derived quantities that are of biological interest are extracted, together with an uncertainty estimate. In this book we use, except in one example, Bayesian methods to assess uncertainty of the estimates. 

Models summarize data. When we have measured the height of 100 trees in a forest and we would like to report these heights to colleagues, we report the mean and the standard deviation instead of reporting all 100 values. The mean and the standard deviation, together with a distributional assumption (e.g., the normal distribution) represent a statistical model that describes the data. We do not need to report all 100 values because the 2 values (mean and standard deviation) describe the distribution of the 100 values sufficiently well so that people have a picture of the heights of the 100 trees. With increasing complexity of the data, we need more complex models that summarize the data in a sensible way.

Statistical models are widely applied because they allow for quantifying uncertainty and making predictions. A well-known application of statistical models is the weather forecast. Additional examples include the prediction of bird or bat collision risks at wind energy turbines based on some covariates, the avalanche bulletins, or all the models used to predict changes of an ecosystem when temperatures rise. Political decisions are often based on models or model predictions. Models are pervasive; they even govern our daily life. For example, we first expected our children to get home before 3:30 p.m. because we knew that the school bus drops them off at 3:24, and a child can walk 200 m in around 4 min. What we had in mind was a model child. After some weeks observing the time our children came home after school, we could compare the model prediction with real data. Based on this comparison and short interviews with the children, we included “playing with the neighbor’s dog” in our model and updated the expected arrival time to 3:45 p.m.


## WHAT THIS BOOK IS ABOUT
This book is about a broad class of statistical models called linear models. Such models have a systematic part and a stochastic part. The systematic part describes how the outcome variable (y, variable of interest) is related to the predictor variables (x, explanatory variables). This part produces the fitted values that are completely defined by the values of the predictor variables. The stochastic part of the model describes the scatter of the observations around the fitted values using a probability distribution. For example, a regression line is the systematic part of the model, and the scatter of the data around the regression line (more precisely: the distribution of the residuals) is the stochastic part.

Linear models are probably the most commonly used models in biology and in many other research areas. Linear models form the basis for many statistical methods such as survival analysis, structural equation analysis, variance components analysis, time-series analysis, and most multivariate techniques. It is of crucial importance to understand linear models when doing quantitative research in biology, agronomy, social sciences, and so on. This book introduces linear models and describes how to fit linear models in R, BUGS, and Stan. The book is written for scientists (particularly organismal biologists and ecologists; many of our examples come from ecology). The number of mathematical formulae is reduced to what we think is essential to correctly interpret model structure and results.

Chapter 2 provides some basic information regarding software used in this book, important statistical terms, and how to work with them using the statistical software package R, which is used in most chapters of the book.

The linear relationship between the outcome y and the predictor x can be straightforward, as in linear models with normal error distribution (normal linear model, LM, Chapter 4). But the linear relationship can also be indirect via a link function. In this case, the direct linear relationship is between a transformed outcome variable and the predictor variables, and, usually, the model has a nonnormal error distribution such as Poisson or binomial (generalized linear model, GLM, Chapter 8). Generalized linear models can handle outcome variables that are not on a continuous and infinite scale, such as counts and proportions.

For some linear models (LM, GLM) the observations are required to be independent of each other. However, this is often not the case, for example, when more than one measurement is taken on the same individual (i.e., repeated measurements) or when several individuals belong to the same nest, farm, or another grouping factor. Such data should be analyzed using mixed models (LMM, GLMM, Chapters 7 and 9); they account for the nonindependence of the observations. Nonindependence of data may also be introduced when observations are made close to each other (in space or time). In Chapter 6 we show how temporal or spatial autocorrelation is detected and we give a few hints about how temporal correlation can be addressed. In Chapter 13, we analyze spatial data using a species distribution example.

Chapter 14 contains examples of more complex analyses of ecological data sets. These models should be understandable with the theory learned in the first part of the book. The chapter presents ideas on how the linear model can be expanded to more complex models. The software BUGS and Stan, introduced in Chapter 12, are used to fit these complex models. BUGS and Stan are relatively easy to use and flexible enough to build many specific models. We hope that this chapter motivates biologists and others to build their own models for the particular process they are investigating.

Throughout the book, we treat model checking using graphical methods with high importance. Residual analysis is discussed in Chapter 6. Chapter 10 introduces posterior predictive model checking. Posterior predictive model checking is used in Chapter 14 to explore the performance of more complex models such as a zero-inflated and a territory occupancy model. Finally, in Chapter 15, we present possible ways to assess prior sensitivity.

The aim of the checklist in Chapter 16 is to guide scientists through a data analysis. It may be used as a look-up table for choosing a type of model depending on the data type, deciding whether to transform variables or not, deciding which test statistic to use in posterior predictive model checking, or understanding what may help when the residual plots do not look as they should. Such look-up tables cannot be general and complete, but the sugges- tions they make can help when starting an analysis.

For the reasons explained in Chapter 3, we use Bayesian methods to draw inference from the models throughout the book. However, the book is not a thorough introduction to Bayesian data analysis. We introduce the principles of Bayesian data analysis that we think are important for the application of Bayesian methods. We start simply by producing posterior distributions for the model parameters of linear models fitted in the widely used open source software R (R Core Team, 2014). In the second part of the book, we introduce Markov chain Monte Carlo simulations for non-mathematicians and use the software OpenBUGS (Lunn et al., 2013) and Stan (mc-stan.org). The third part of the book includes, in addition to the data analysis checklist, example text for the presentation of results from a Bayesian data analysis in a paper. We also explain how the methods presented in the book can be described in the methods section of a paper. Hopefully, the book provides a gentle introduction to applied Bayesian data analysis and motivates the reader to deepen and expand knowledge about these techniques, and to apply Bayesian methods in their data analyses.


## FURTHER READING {-} 
Gelman and Hill (2007) teach Bayesian data analysis using linear models in a very creative way, with examples from the social and political sciences. Kruschke (2011) gives a thorough and very understandable introduction to Bayesian data analysis. McCarthy (2007) concisely introduces Bayesian methods using WinBUGS. Ke ́ry (2010) gives an introduction to linear models using Bayesian methods with WinBUGS. Stauffer (2008) works practically through common research problems in the life sciences using Bayesian methods.

Faraway (2005, 2006) and Fox and Weisberg (2011) provide applied introductions to linear models using frequentist methods in R. Note that there is an extensive erratum to Faraway (2006) on the web. Zuur et al. (2009, 2012) are practical and understandable introductions to linear models in R with a particular focus on complex real ecological data problems such as nonindependent data. Zuur et al. (2012) also introduce Bayesian methods. A more theoretical approach, including R code, is Aitkin et al. (2009). We can also recommend the chapters introducing generalized linear models in Wood (2006).
